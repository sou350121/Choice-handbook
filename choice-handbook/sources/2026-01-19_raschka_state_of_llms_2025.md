# Digest：Raschka《State of LLMs 2025》——“推理模型之年”、Benchmaxxing 与工具/推理时扩展

## 来源与类型

- **作者/材料**：Sebastian Raschka，State of LLMs 2025（博客文章）
- **原文**：`https://magazine.sebastianraschka.com/p/state-of-llms-2025`
- **材料形态**：年度复盘/观点文（工程视角，含大量经验判断与预测）
- **一手/二手**：一手观点（作者本人复盘）；你提供的版本为“机器之心编译/整理”，以原文为准
- **可追溯性**：可追溯到原文段落；文中部分细节与数字来自论文/模型卡/社区观察，需分别核验
- **潜在盲区**：作者视角偏工程与开源生态；对商业内部数据/真实线上指标引用有限

## 主题标签

推理模型｜RLVR｜GRPO｜推理时扩展｜工具使用｜MoE｜高效注意力｜扩散模型｜评测与刷榜｜Benchmaxxing｜持续学习｜私有数据｜编码与协作边界

## 文章主张（作者视角）

作者认为 2025 的中心是“推理模型（Reasoning LLMs）”：

- **Scaling 仍然有效**，但主战场从“参数堆叠”转向“推理侧强化”与“后训练（尤其 RLVR + GRPO）”
- **DeepSeek R1**（开源权重 + RLVR/GRPO）引发“DeepSeek 时刻”：成本经济学被重估，推理模型路线被广泛跟进
- **架构层面收敛**：开源权重 LLM 普遍收敛到 MoE + 至少一种高效注意力（GQA / sliding window / MLA 等）
- **推理时扩展 + 工具使用**是能力提升的另一条主线（不是只靠训练/参数）
- **年度词汇：Benchmaxxing（极限刷榜）**：基准分数越来越不可信，尤其当测试集被直接优化/污染
- **现实工作体验**：LLM 是“超能力工具”而不是替代品；滥用可能造成空虚与职业倦怠
- **优势来源：私有数据**：未来竞争更依赖领域数据与内部训练/后训练；数据出售给外部大厂可能短视
- **预测**：扩散模型会在低延迟任务进入消费级；RLVR 将扩展到数学/代码之外；开源会更普遍工具使用；RAG 作为默认方案可能淡出；更多“进步”来自工具与推理时扩展而非核心模型本身

## 可抽取资产（Asset Extraction）

### 定义（概念边界）

- **推理模型（Reasoning LLMs）**：生成包含中间步骤/解释的输出，往往提升最终答案准确性（作者在 LLM 语境下的定义）。
- **RLVR**：可验证奖励强化学习，用确定性/可自动验证信号进行后训练（早期主要在数学/代码）。
- **GRPO**：一种 RL 训练方法/算法变体，被作者称为年度研究宠儿；大量工程技巧显著影响训练稳定性。
- **推理时扩展（Inference-time scaling）**：在生成答案时投入更多时间/样本/自一致性/自精炼迭代，以换取准确性。
- **工具使用（Tool use）**：让模型通过搜索、计算器等工具获得可验证外部信息以降低幻觉，但带来权限/安全问题。
- **Benchmaxxing**：把提升基准分数本身当目标，导致评测失真。
- **持续学习（Continual learning）**：不从头训练而持续更新知识；挑战是灾难性遗忘。

### 变量（关键量）

- 训练侧：RLVR 覆盖的可验证任务范围、GRPO 训练稳定性技巧、后训练算力预算
- 推理侧：推理 token / 采样次数 / 自精炼迭代次数、延迟与成本阈值
- 架构侧：MoE 比例、注意力效率机制、序列长度与成本
- 评测侧：公开测试集污染程度、对抗/回归集质量、真实任务分布偏差
- 产品侧：工具权限边界、审计/回放、用户体验对延迟的容忍

### 机制（因果链 / 互动算子）

- **可验证奖励 + 大规模后训练 → 推理能力强化**（尤其在数学/代码）
- **训练/推理/工具多杠杆叠加 → 能力提升更像组合拳**（不再是单一突破）
- **公开基准被直接优化 → 分数不再可靠**（必要门槛仍在，但高分不代表更好）
- **工具使用降低幻觉 → 同时扩大安全攻击面**（权限越大风险越高）
- **私有数据难外售 → 内部模型与定制后训练成为优势来源**

### 反例/失败模式（尽头线索）

- Benchmaxxing：分数好看但用户体验差、真实任务失败
- 推理时扩展：准确性提升但成本/延迟不可承受
- 工具使用：权限失控导致安全事故或破坏性操作
- 持续学习：灾难性遗忘导致旧能力退化

### 可验证预测（假设/推演）

- RLVR 将扩展到数学/代码之外（化学/生物等），但需要更强的可验证信号设计
- 评测将继续向“真实任务回归集 + 对抗集 + 人类实测”迁移
- 低延迟任务上，扩散式文本模型可能成为有竞争力的替代方案

## 输出去向建议

- **世界理解**：`world_understanding/state_of_llms_2025_raschka.md`
- **可衍生清单**：评测与工具权限清单（如何防 Benchmaxxing、如何设停机点）

