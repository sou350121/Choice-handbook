# Digest：LLM 预测金融市场 —— 推理还是“记忆偷看”？（LAP / Lookahead Bias）

## 来源与类型

- **材料形态**：论文解读型文章（含方法与实验结果叙述）
- **一手/二手**：二手（未提供论文原文链接，需补原文核验）
- **可信度提示**：
  - 属于“方法论/风险诊断”类材料
  - 关键细节（样本、模型、统计显著性）需以原论文为准

## 主题标签

LLM｜金融预测｜回测｜前视偏差｜成员推断｜记忆 vs 推理｜LAP 指标｜样本外检验

## 核心论点（可抽取资产）

### 1) LLM 金融预测存在“训练记忆偷看”风险
- 模型可能已在训练语料中见过“事件 + 结果”文本，导致回测中“看似预测”，实为回忆。
- 本质是新形态前视偏差（Lookahead Bias）。

### 2) LAP：用“模型不确定词”判断是否见过文本
- 取 token 预测概率最低的 20% 词，计算其平均概率作为 LAP。
- **LAP 越高** → 模型越“熟悉”该文本，可能训练中见过。

### 3) “越熟越准”：LAP × 预测交互项显著
- 预测准确率提高的来源，部分是“熟悉度放大”。
- 交互项显著 → 预测力来自记忆而非机制推理。

### 4) 样本外安慰剂：截断训练数据
- 采用训练截止 2023 年中的模型，用 2023 年 9 月之后新闻测试。
- 样本外交互项消失 → 记忆效应被剥离。

## 可证伪变量与观察信号（示例）

- **LAP-准确率联动**：样本内显著，样本外显著消失。
- **小盘股效应**：小盘股更易形成“事件—结果”记忆模式。
- **诊断工具价值**：只要能获取 token 概率，就能做“前视偏差体检”。

---

## 输出去向建议

- **世界理解落点**：`world_understanding/llm_finance_lap_lookahead_bias_2026.md`
- **可衍生猜想**：H-0031（LLM 预测能力部分由训练记忆驱动，需 LAP 体检）
