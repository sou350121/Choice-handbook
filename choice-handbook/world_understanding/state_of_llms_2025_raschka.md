# 2025 属于「推理模型」的一年（Raschka）：RLVR/GRPO、Benchmaxxing 与“多杠杆进步”

> 这篇把 Raschka 的年度复盘收敛成“世界理解”与可执行判断：2025 的主线不再是单纯参数堆叠，而是后训练（RLVR/GRPO）、推理时扩展、工具使用与效率架构的组合拳；与此同时，Benchmaxxing 让评测进入困难时期。
>
> 来源 digest：`sources/2026-01-19_raschka_state_of_llms_2025.md`（原文：`https://magazine.sebastianraschka.com/p/state-of-llms-2025`）

---

## 概述（这篇解决什么选择/误区）

这篇解决三类常见误区：

- **误区 A：只看训练侧 scaling**：认为“更大参数/更多预训练”就是全部答案。
- **误区 B：把基准分数当现实能力**：忽视 Benchmaxxing 与测试集污染/直接优化。
- **误区 C：把 LLM 当替代品**：忽视它更像“超能力工具”，以及过度外包思考带来的技能退化与倦怠风险。

作者的元结论是：**2025 的进步不是单一突破，而是多个杠杆在多条战线上同时推进**（架构、数据与中期训练、后训练 RLVR/GRPO、推理时扩展、工具调用、效率与延迟工程）。

---

## 框架/模型（1–3 个，给出使用条件）

### 1) “推理模型之年”：RLVR + GRPO 把后训练变成主战场

- **观点**：Scaling 仍有效，但真正“感觉上的变化”来自推理模型与后训练强化（尤其 RLVR + GRPO）。
- **关键机制**：可验证奖励让后训练能在大量数据上进行，推动推理能力在数学/代码等可验证任务上快速提升。

**适用**：你在解释 2025 以来推理模型为何陡增、为何“思考/Thinking”变体普及。  
**不适用**：你要提升的是非可验证领域的对齐与价值偏好（需要不同信号设计与约束）。

### 2) “进步来自推理端与工具端”：推理时扩展 + 工具使用

- **推理时扩展**：花更多时间/采样/自一致性/自精炼，换更高准确性（但延迟与成本上升）。
- **工具使用**：用搜索、计算器等外部工具降低幻觉与错误（但权限与安全风险更高）。

**适用**：你在做“准确性 > 延迟/成本”的任务（难数学/难代码/研究辅助）。  
**不适用**：你必须低延迟、强成本约束，且不允许高风险工具权限。

### 3) 评测困境：Benchmaxxing 下的“必要门槛 ≠ 排名可信”

作者提出的实用立场：

- **低分**通常意味着模型不行（必要门槛）
- **高分**不等于更好（排名越来越不可信）

**适用**：你在选型、采购、做内部评测与回归体系。  
**不适用**：你只需要非常单一、确定性的任务指标（LLM 往往不是这种）。

---

## 材料分类与索引

- **类型**：年度复盘/观点文（工程视角 + 预测）
- **主题**：RLVR/GRPO、推理时扩展、工具使用、MoE/高效注意力、Benchmaxxing、持续学习、私有数据与企业优势、编码/写作/研究的协作边界
- **可信度**：
  - 第一手/二手：第一手观点；你提供的为编译版，以原文为准
  - 可追溯性：观点可追溯到原文；部分数字/案例需回到论文/模型卡核验
  - 盲区：真实线上指标与商业内部细节引用有限
- **输出去向**：`world_understanding/`

---

## 降维解剖（把“推理模型之年”压成可计算骨架）

### 第一性扫描（事实/约束/资源/风险）

- **可验证信号存在** → RLVR 可规模化 → 推理能力强化更可行（数学/代码先行）
- **推理越强常伴随更长输出** → 延迟与成本上升 → 不是所有场景都适配
- **工具能补事实与计算** → 幻觉下降 → 但权限扩大带来安全与破坏风险
- **评测公开/被优化** → 分数不再可靠 → 必须建立自己的回归与对抗集

### 根本问题 $\\mathcal{O}$：你在最大化什么？

一个可执行版本：

- **最大化**：真实任务成功率（而非榜单分数） × 可持续性（成本/延迟/风险可控）
- **约束**：推理预算、工具权限、安全合规、工程可维护性、数据与反馈回路

### 核心变量（≤10）+ 算子（≤5）

- **变量**：RLVR 覆盖任务范围、GRPO 训练稳定性、推理 token 预算、采样/自精炼次数、工具权限范围、审计回放完备性、成本/延迟阈值、评测污染程度、私有数据可用性、灾难性遗忘强度。
- **算子**：后训练优化（RLVR/GRPO）、推理时扩展（self-consistency/self-refine）、工具调用（search/calc）、评测回归（回归集+对抗集）、权限治理（allowlist/审计/停机）。

### 阶段切换信号（3 个）

1) 真实任务成功率提升主要来自“推理端与工具端”，而非参数扩张  
2) 评测从“看榜单”转向“看回归集 + 对抗集 + 真实用户任务”  
3) 企业竞争优势从“模型本身”向“私有数据 + 内部定制 + 权限与流程”迁移

---

## 比较思考（发展史 × 情景 × 信号）

### 结构相似的祖先（机制类比）

- **编译器/库/自动化工具链**：降低生产边际成本，但对“专家判断/架构能力”的需求并未消失。
- **早期搜索引擎 + 浏览器插件**：工具把能力外包给外部系统，带来巨大收益，同时引入新的安全边界问题。

### 未来情景（保守/基准/激进）+ 观察信号（假设/推演）

- **保守**：Benchmaxxing 持续，评测失真；推理时扩展主要用于少数高价值任务。  
  - 信号：榜单大起大落；用户体感与分数长期脱钩。
- **基准**：工具使用与权限治理成熟；开源模型逐步补齐本地工具与 agent 能力；RAG 默认地位下降。  
  - 信号：出现更统一的工具/数据访问标准；长上下文与小模型改进显著。
- **激进**：低延迟扩散式文本模型进入消费级；RLVR 扩展到更多领域；持续学习出现关键突破。  
  - 信号：扩散模型在低延迟代码补全等任务形成稳定优势；灾难性遗忘被显著缓解。

---

## 尽头坐标（唐诺）

### 远方尽头

LLM 从“能说”走向“能可靠完成任务”：可评估、可回归、可审计、可控成本与延迟、可安全使用工具。

### 现实尽头（停止处）

- **评测尽头**：分数越来越像噪声，团队在错误目标上优化
- **成本/延迟尽头**：推理时扩展带来预算爆炸，无法规模化
- **权限尽头**：工具使用引发安全事故，迫使系统收缩到“只能聊天”
- **技能/倦怠尽头**：过度外包导致空虚与技能退化，长期生产力下降

### 退出条件 + 重启条件

- **退出条件（停机点）**
  - 连续 ___ 次迭代只提升榜单分数，真实任务成功率无提升
  - 推理时扩展导致单任务成本/延迟超过阈值（___ 元/次、___ 秒）
  - 工具权限触发高危事件（数据泄露/破坏性操作）≥ ___ 次
- **重启条件**
  - 回归集与对抗集建立并可稳定回归
  - 权限/审计/停机机制完整（可追责可复盘）
  - 推理预算分层策略上线（路由/缓存/按需推理）

---

## 短/中/长期利益（1–3 个月 / 1–3 年 / 5–10 年）

- **短期**：用回归集替代榜单；把工具权限与审计做成默认；按需推理（预算分层）
- **中期**：开源生态补齐本地工具与 agent；更高效架构普及（MoE/高效注意力/工程优化）
- **长期**：多范式模型（含扩散）在低延迟任务落地；持续学习取得突破；评测体系更一致透明

---

## MUST / SHOULD / MAY 清单

- **MUST**
  - 建自己的真实任务回归集（否则你在优化幻觉）
  - 工具使用必须有权限边界与审计回放（能停机、能追责）
  - 推理预算必须量化（成本/延迟/准确性三者一起看）
- **SHOULD**
  - 将推理时扩展变成“按需能力”，而不是默认全开
  - 对 Benchmaxxing 做对抗测试（换提示、换分布、换工具链）
  - 对关键系统保留人类在驾驶座（尤其高正确性与高风险任务）
- **MAY**
  - 评估扩散式文本模型在低延迟任务的可行性
  - 在可验证领域探索 RLVR/GRPO 的可复现训练流程

---

## 练习（可复制填写）

- 我关心的任务：__________  
- 我目前的评测方式：榜单 / 回归集 / 线上指标（选一）  
- 我最担心的尽头：评测 / 成本延迟 / 权限安全 / 倦怠（选一）  
- 我允许的推理预算：___ tokens / ___ 秒 / ___ 元  
- 我的退出条件：__________  
- 我的重启条件：__________

---

## Plan Prompt（可直接复制给 Agent 执行｜小成本验证）

```text
你是执行代理。请在不编造信息的前提下，帮我把“Raschka 2025 年度复盘”的要点落到我的场景里，完成一次小成本验证。

## 背景
我的场景/产品/工作流：<一句话>
我目前的模型形态：<普通LLM/推理模型/带工具/agent>
我目前的评测方式：<榜单/内部回归/线上指标>

## 目标（要拿到的证据）
- 证据1：给出一份最小“真实任务回归集”（10–30 条）+ 对抗集（5–10 条）方案
- 证据2：给出工具权限最小方案（allowlist、审计字段、停机点）
- 证据3：给出推理预算分层方案（什么时候启用推理时扩展，阈值与判定）
- 证据4：输出退出条件与重启条件（可观测阈值）

## 约束
- 时间盒：90 分钟
- 投入上限：<钱/人天/算力>
- 隐私：不要写入任何真实个人隐私或敏感信息

## 你要做的事
1) 把最危险假设写成可证伪陈述（3 条）
2) 设计最小实验（动作+成本+预期信号+判定标准）
3) 写出退出条件与重启条件
4) 输出一段可直接粘贴到 `worksheets/decision_one_pager.md` 的一页总结
```

