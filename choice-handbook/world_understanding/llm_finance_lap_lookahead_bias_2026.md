# LLM 金融预测：推理还是“记忆偷看”？（LAP × 前视偏差体检）

> Evidence：`sources/2026-01-24_llm_finance_lap_lookahead_bias.md`

---

## 概述

这是一篇 **方法论型信号**：LLM 在金融预测里“越准，越可能在偷看”。核心是把“前视偏差”从数据泄露扩展到**模型记忆泄露**，并给出一个低成本的体检指标（LAP）。

## 结论（当前）

- **结论**：观察名单（50%）  
- **适用边界**：LLM 做新闻/电话会议/文本驱动的预测与回测。  
- **为什么不是强结论**：缺原文复核；不同模型与数据源可能结果不同。

## 框架使用

- 01 决策质量（验证与可证伪）  
- 02 期权价值（小成本验证）  
- 03 尽头思维（退出条件）  
- 05 推理工具箱（机制/变量/信号）

---

## 关键信号簇（未核验）

### A) “记忆偷看”的新型前视偏差
- 模型训练语料覆盖“事件 + 结果” → 回测里看似预测实为回忆。  

### B) LAP 指标：熟悉度体检
- 取“最不确定词”的平均概率作为熟悉度。  
- **LAP 越高** → 可能见过该文本/事件。  

### C) “越熟越准”的交互效应
- LAP × 预测交互项显著 → 准确率依赖熟悉度。  

### D) 样本外安慰剂
- 训练截止模型 + 未来新闻测试 → 交互项消失。

---

## 机制链条（短而密）

1) **训练语料覆盖事件结果 → 模型形成“事件—结果”模板 → 回测预测被记忆放大**。  
2) **LAP 高 → 熟悉度高 → 预测更准（但来自记忆而非因果机制）**。  
3) **样本外截断 → 记忆效应消失 → 交互项消退**。

---

## 反证信号（出现就降级）

- 样本外区间仍出现显著正向 LAP×预测交互项。  
- 更换模型/语料后，LAP 与准确率无稳定关系。  
- 纯数值因子模型出现同样“熟悉度效应”。

---

## 最短探针（30d）

- **探针 A（体检）**：对现有 LLM 回测加入 LAP 诊断。  
  - 观察：LAP-准确率联动是否显著。  
- **探针 B（样本外）**：用训练截止模型 + 未来新闻测试。  
  - 观察：交互项是否消失。  
- **探针 C（小盘股）**：分组检验小盘股是否更“熟悉”。

---

## 退出条件 + 重启条件

- **退出条件**：样本外仍显著；LAP 与预测无稳定关系。  
- **重启条件**：多个模型/数据源下出现稳定的“熟悉度放大”模式。

---

## 年代镜头（当时的人看到什么）

- 回测很漂亮，但解释不清“预测力来源”。  
- LLM 成为“叙事记忆库”，风险从数据泄露迁到模型本体。

## 分叉点（当时可选路径与代价）

1) **继续堆模型**：结果漂亮，但可信度不明。  
2) **先体检再扩展**：速度慢，但可信度可积累。  
3) **做严格样本外**：成本更高，但可切断记忆效应。

## 收敛（我更确定的未来来自哪里）

- LLM 预测必须“记忆体检”与“样本外截断”作为门槛。  
- 预测准确率不是核心，**来源可解释性**才是核心资产。

---

## 可投資標的（不设）

> 这是一种方法论与风险识别框架，不直接给标的。
