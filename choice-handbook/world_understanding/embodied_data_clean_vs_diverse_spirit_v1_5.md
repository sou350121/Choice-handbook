# 具身数据范式：别追求“干净”，要追求“有用 + 多样”（Spirit v1.5 / 高阳）

> 核心观点：抛弃几乎所有“保证干净数据”的规则，只保留一条原则——做一些有用的事情；用目标驱动的自由过程换取多样性，再用规模化把能力推上去。
>
> 来源 digest：`sources/2026-01-19_gaoyang_spirit_v1_5_clean_data_enemy.md`（含官方 blog：`https://www.spirit-ai.com/en/blog/spirit-v1-5`）

---

## 概述（这篇解决什么选择/误区）

在机器人/具身智能的数据问题上，最常见的误区是把：

- **高质量数据 = 干净数据（clean）**  
- **模型能学会 = 数据要被强约束、强筛选、强脚本化**

这篇材料提出反直觉主张：对“通用 robot foundation model”而言，**过于干净的数据可能是敌人**。更好的方向是：

- **目标驱动**（只规定“做什么有用的事”）
- **过程自由**（允许操作者随机发挥）
- **多样性优先**（diversity）
- **然后 scale**（Bitter Lesson：Diversity，然后 Scale）

---

## 框架/模型（1–3 个，给出使用条件）

### 1) “Clean vs Diverse”不是数据卫生问题，而是泛化策略选择

- **Clean（强约束/强脚本）**：易收敛、复现难度低、单任务成功率好看
- **Diverse（弱约束/目标驱动）**：更像真实生活流，包含切换、失败恢复、遮挡、不可达等复杂性

**适用**：你在做 foundation model 预训练、跨任务迁移、希望模型学“技能组合”而非“单动作”。  
**不适用**：你只做一个固定任务、固定环境、且更看重短期收敛与可控复现（但也要防止过拟合）。

### 2) “只保留一条原则”：目标驱动采集（Goal-driven collection）

把采集规则从“如何做”改成“做成什么”：

- 规则从脚本变成目标（high-level objective）
- 过程允许自由发挥（子任务自然串联）
- 记录连续经验流（而不是孤立片段）

**适用**：你想提高数据多样性，并降低“每个新任务都要重新设计采集流程”的管理成本。  
**不适用**：你没有清晰目标、也没有最小安全边界，导致“多样”退化为随机噪声。

### 3) VLA vs 世界模型：不是路线对立，而是增强模块

在“通用操作”问题上，最自然 I/O 是：

- **视觉 + 语言 → 动作**

只要 I/O 是 V+L→A，本质上就是 VLA。所谓世界模型更多是作为增强模块（例如预测未来图像）提升泛化能力，而不是与 VLA 对立的路线。

---

## 材料分类与索引

- **类型**：专访对话 + 官方博客翻译/整理（二手材料，以原文为准）
- **主题**：数据范式（clean vs diverse）、VLA 与世界模型关系、数据配方探索、仿真/人类数据取舍、Bitter Lesson
- **可信度提示**：
  - 文中的量化声称与榜单结果需回到官方材料核验
  - “开源数据集几乎都是 clean”属于立场与观察，需明确你的定义与抽样范围
- **可抽取资产**：见 `sources/2026-01-19_gaoyang_spirit_v1_5_clean_data_enemy.md`

---

## 降维解剖（把“数据范式”压成可计算骨架）

### 第一性扫描（事实/约束/资源/风险）

- 机器人数据采集天然昂贵：脚本化与质控会把管理成本做成线性增长
- 真实世界任务天然“脏”：遮挡、不可达、失败恢复、状态切换是常态
- foundation model 目标不是复现单一轨迹，而是学会可迁移技能组合

### 根本问题 $\\mathcal{O}$：你在最大化什么？

一个可执行目标函数：

- **最大化**：跨任务迁移能力 + few-shot 微调效率
- **约束**：采集成本、管理成本、训练稳定性、风险与安全边界

### 核心变量（≤10）+ 算子（≤5）

- **变量**：任务多样性、连续性（是否串联）、失败恢复比例、环境变化幅度、遮挡/可达性分布、目标完成率、数据规模、采集人均效率、研究人员介入成本、微调样本需求。
- **算子**：目标定义、采集自由度设置、最小安全约束、训练（预训练+微调）、评测（迁移/泛化/恢复）。

### 阶段切换信号（3 个）

1) 数据规模增长下能力斜率仍大（scaling 继续有效）  
2) 少样本微调步骤显著下降（迁移变快）  
3) 从“单任务成功率”转向“跨任务组合与恢复能力”的评测体系建立

---

## 比较思考（发展史 × 情景 × 信号）

### 结构相似的祖先（机制类比）

- **自动驾驶数据飞轮**：真实世界的“长尾与脏”不可避免；关键是把采集、标注/管理、训练、回归做成系统。
- **机器人 sim-to-real**：追求“可控仿真/可控流程”能起步，但泛化往往卡在真实世界的混乱分布。

### 未来情景（保守/基准/激进）+ 观察信号（假设/推演）

- **保守**：clean 数据仍主导，模型以“更易复现”换“较弱泛化”。  
  - 信号：评测仍以单任务成功率为主；跨任务迁移提升慢。
- **基准**：目标驱动多样化采集成为主流 recipe；配合更好的训练与评测体系。  
  - 信号：更少人工规则、更大规模采集；few-shot 微调显著更快。
- **激进**：出现具身版“GPT-3→GPT-4”级模型跃迁（访谈期待）。  
  - 信号：in-context learning 在操作领域真正可用（给演示就能学会）。

---

## 尽头坐标

### 远方尽头

机器人能在真实、混乱的家庭/开放环境里完成通用操作：会组合技能、会恢复、会在新环境里快速适配。

### 现实尽头（停止处）

- **过度 clean 的尽头**：泛化弱、遇到遮挡/不可达/失误恢复就崩
- **无目标的“脏”尽头**：多样性退化为噪声，训练不收敛或学不到可迁移结构
- **评测尽头**：只盯单任务成功率，误判模型是否在变“通用”
- **组织尽头**：管理与质控成本线性上升，规模化失败

### 退出条件 + 重启条件

- **退出条件（停机点）**
  - 数据更“干净”但迁移/泛化指标无提升（连续 ___ 次迭代）
  - 多样化采集导致训练不稳定且无法归因（连续 ___ 次 run）
  - 评测只剩单任务成功率，无法反映通用能力进展（持续 ___ 周）
- **重启条件（证据门槛）**
  - 迁移评测与恢复评测可稳定回归（回归集建立）
  - 目标驱动采集的人均效率提升（≥ ___%）且管理成本不线性增长
  - few-shot 微调样本需求下降（≥ ___%）

---

## MUST / SHOULD / MAY 清单

- **MUST**
  - 定义“有用目标”（否则多样性会变噪声）
  - 建立跨任务迁移与恢复评测（别只看单任务成功率）
  - 记录连续轨迹与关键模态（视觉 + 关节/末端位姿等）
- **SHOULD**
  - 放松过程约束，保留最小安全边界
  - 让采集者自由发挥，鼓励任务串联与失败恢复
  - 随模型升级持续调整数据配方（recipe 不是一次性）
- **MAY**
  - 探索 in-context learning 的具身形式（演示→学会）
  - 在真实数据足够后逐步减少仿真依赖（以实际增益为准）

---

## 可投資標的（Long / Hedge / Short）

> 仅用于把“世界理解”翻译成可执行的交易表达，不构成投资建议。

**观点摘要**：具身数据的“护城河”更可能来自规模化采集与多样性配方，而不是过度 clean 的流程；因此受益链条偏向算力/传感器/数据中心与能够规模化落地的机器人与自动化生态。

### Long（做多：我相信它会发生）

- **主题**：数据规模化与采集基础设施（算力、传感器、渲染/仿真工具链、数据中心）  
  - **代表性标的（2–5）**：`NVDA`（训练/推理底座）、`SMH`（半导体篮子）、`BOTZ`/`ROBO`（机器人篮子，二选一）、`EQIX`（数据中心/互联）、`U`（工具链候选：渲染/仿真相关，按你风险偏好与理解决定是否纳入）  
  - **加密（可选）**：若把“数据 + 风险偏好”做 beta 暴露的一部分，可用 `BTC`/`BTC` ETF（视账户）作为高波动表达之一

### Hedge（对冲：我怕的是什么）

- **风险 1：隐私/合规/数据获取受限** → **工具**：分散化（篮子化）+ 指数 put；必要时减少“依赖数据获取叙事”的单票暴露  
- **风险 2：利率上行压制长久期成长估值** → **工具**：久期对冲（如 `TLT` 或利率相关工具，视账户）  
- **风险 3：制造业周期下行** → **工具**：工业/半导体篮子对冲或降低仓位

### Short（做空：我不相信它会发生，或认为被高估）

- **方向**：把“clean 数据=泛化”当作核心卖点的单一产品叙事（在真实世界分布下可能脆弱）。  
  - **表达方式**：优先用机器人/科技主题 ETF 的 put 或对冲对表达，避免裸空单票。  
  - **失效条件**：如果出现可回归证据显示“更 clean 的流程”在多任务迁移与恢复上持续胜出，应降低反向表达

### 观察信号（用于更新仓位）

- **信号 1（配方）**：行业是否从“数据清洁规则”转向“目标驱动 + 多样性 + 规模化”的 recipe  
- **信号 2（模态）**：触觉/力反馈/视触觉等关键模态是否普及（决定接触技能上限）  
- **信号 3（评测）**：评测是否从单任务成功率转向跨任务迁移 + 失败恢复  
- **复盘频率**：每月

---

## Plan Prompt（可直接复制给 Agent 执行｜小成本验证）

```text
你是执行代理。请在不编造信息的前提下，帮我把“clean vs diverse 的具身数据范式”落到我的数据采集与训练里，完成一次小成本验证。

## 背景
我的机器人平台/传感器：<相机/关节角/末端位姿…>
我现在的数据范式：<clean脚本化 / 目标驱动多样化 / 混合>
我关心的通用能力：<跨任务迁移/失败恢复/新环境适配>

## 目标（要拿到的证据）
- 证据1：定义 3 个“有用目标”，并给出每个目标的最小安全边界与允许自由度
- 证据2：设计一个 A/B 采集对比（clean vs diverse），总数据量相同，评测迁移/恢复
- 证据3：给出评测回归集（至少 10 个任务/场景片段）与判定标准
- 证据4：写出退出条件与重启条件（可观测阈值）

## 约束
- 时间盒：7 天（可调整）
- 投入上限：<人天/设备占用/预算>
- 隐私：不要写入任何真实个人隐私或敏感信息

## 你要做的事
1) 把最危险假设写成可证伪陈述（3 条）
2) 设计最小实验（动作+成本+预期信号+判定标准）
3) 写出退出条件与重启条件
4) 输出一段可直接粘贴到 `worksheets/decision_one_pager.md` 的一页总结
```

