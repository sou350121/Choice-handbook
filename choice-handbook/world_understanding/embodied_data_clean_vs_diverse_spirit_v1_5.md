# 具身数据范式：别追求“干净”，要追求“有用 + 多样”（Spirit v1.5 / 高阳）

> 核心观点：抛弃几乎所有“保证干净数据”的规则，只保留一条原则——做一些有用的事情；用目标驱动的自由过程换取多样性，再用规模化把能力推上去。
>
> 来源 digest：`sources/2026-01-19_gaoyang_spirit_v1_5_clean_data_enemy.md`（含官方 blog：`https://www.spirit-ai.com/en/blog/spirit-v1-5`）

---

## 概述（这篇解决什么选择/误区）

在机器人/具身智能的数据问题上，最常见的误区是把：

- **高质量数据 = 干净数据（clean）**  
- **模型能学会 = 数据要被强约束、强筛选、强脚本化**

这篇材料提出反直觉主张：对“通用 robot foundation model”而言，**过于干净的数据可能是敌人**。更好的方向是：

- **目标驱动**（只规定“做什么有用的事”）
- **过程自由**（允许操作者随机发挥）
- **多样性优先**（diversity）
- **然后 scale**（Bitter Lesson：Diversity，然后 Scale）

---

## 框架/模型（1–3 个，给出使用条件）

### 1) “Clean vs Diverse”不是数据卫生问题，而是泛化策略选择

- **Clean（强约束/强脚本）**：易收敛、复现难度低、单任务成功率好看
- **Diverse（弱约束/目标驱动）**：更像真实生活流，包含切换、失败恢复、遮挡、不可达等复杂性

**适用**：你在做 foundation model 预训练、跨任务迁移、希望模型学“技能组合”而非“单动作”。  
**不适用**：你只做一个固定任务、固定环境、且更看重短期收敛与可控复现（但也要防止过拟合）。

### 2) “只保留一条原则”：目标驱动采集（Goal-driven collection）

把采集规则从“如何做”改成“做成什么”：

- 规则从脚本变成目标（high-level objective）
- 过程允许自由发挥（子任务自然串联）
- 记录连续经验流（而不是孤立片段）

**适用**：你想提高数据多样性，并降低“每个新任务都要重新设计采集流程”的管理成本。  
**不适用**：你没有清晰目标、也没有最小安全边界，导致“多样”退化为随机噪声。

### 3) VLA vs 世界模型：不是路线对立，而是增强模块

在“通用操作”问题上，最自然 I/O 是：

- **视觉 + 语言 → 动作**

只要 I/O 是 V+L→A，本质上就是 VLA。所谓世界模型更多是作为增强模块（例如预测未来图像）提升泛化能力，而不是与 VLA 对立的路线。

---

## 材料分类与索引

- **类型**：专访对话 + 官方博客翻译/整理（二手材料，以原文为准）
- **主题**：数据范式（clean vs diverse）、VLA 与世界模型关系、数据配方探索、仿真/人类数据取舍、Bitter Lesson
- **可信度提示**：
  - 文中的量化声称与榜单结果需回到官方材料核验
  - “开源数据集几乎都是 clean”属于立场与观察，需明确你的定义与抽样范围
- **可抽取资产**：见 `sources/2026-01-19_gaoyang_spirit_v1_5_clean_data_enemy.md`

---

## 降维解剖（把“数据范式”压成可计算骨架）

### 第一性扫描（事实/约束/资源/风险）

- 机器人数据采集天然昂贵：脚本化与质控会把管理成本做成线性增长
- 真实世界任务天然“脏”：遮挡、不可达、失败恢复、状态切换是常态
- foundation model 目标不是复现单一轨迹，而是学会可迁移技能组合

### 根本问题 $\mathcal{O}$：你在最大化什么？

一个可执行目标函数：

- **最大化**：跨任务迁移能力 + few-shot 微调效率
- **约束**：采集成本、管理成本、训练稳定性、风险与安全边界

### 核心变量（≤10）+ 算子（≤5）

- **变量**：任务多样性、连续性（是否串联）、失败恢复比例、环境变化幅度、遮挡/可达性分布、目标完成率、数据规模、采集人均效率、研究人员介入成本、微调样本需求。
- **算子**：目标定义、采集自由度设置、最小安全约束、训练（预训练+微调）、评测（迁移/泛化/恢复）。

### 阶段切换信号（3 个）

1) 数据规模增长下能力斜率仍大（scaling 继续有效）  
2) 少样本微调步骤显著下降（迁移变快）  
3) 从“单任务成功率”转向“跨任务组合与恢复能力”的评测体系建立

---

## 比较思考（发展史 × 情景 × 信号）

### 结构相似的祖先（机制类比）

- **自动驾驶数据飞轮**：真实世界的“长尾与脏”不可避免；关键是把采集、标注/管理、训练、回归做成系统。
- **机器人 sim-to-real**：追求“可控仿真/可控流程”能起步，但泛化往往卡在真实世界的混乱分布。

### 未来情景（保守/基准/激进）+ 观察信号（假设/推演）

- **保守**：clean 数据仍主导，模型以“更易复现”换“较弱泛化”。  
  - 信号：评测仍以单任务成功率为主；跨任务迁移提升慢。
- **基准**：目标驱动多样化采集成为主流 recipe；配合更好的训练与评测体系。  
  - 信号：更少人工规则、更大规模采集；few-shot 微调显著更快。
- **激进**：出现具身版“GPT-3→GPT-4”级模型跃迁（访谈期待）。  
  - 信号：in-context learning 在操作领域真正可用（给演示就能学会）。

---

## 年代镜头（当时的人看到什么）

- **当时约束**：机器人数据采集昂贵且难规模化；“干净/可控/可复现”是工程直觉的默认答案。  
- **当时可见信号**：单任务脚本数据能把成功率做得很好，但跨任务迁移与失败恢复仍弱。  
- **当时主流信念**：先把数据做干净、把流程做标准化，模型自然会更强。  
- **当时盲区**：真实世界的分布就是“脏且混乱”；过度 clean 会把关键长尾与恢复行为从数据里删掉。

## 分叉点（当时可选的路径与代价）

- **路径 A：继续 clean（强约束/强脚本）**  
  - 代价：短期好看、长期泛化弱；每加一个任务就要重做流程，管理成本线性上升。
- **路径 B：目标驱动 diverse（过程自由）**  
  - 代价：短期更难收敛、更难复现；必须有回归集与最小安全边界，否则多样性会退化成噪声。
- **路径 C：混合路线（先 diverse 找结构，再用 clean 精修）**  
  - 代价：对组织与工具链要求更高；但更符合“先探索、后固化”的规模化路径。

## 收敛（我更确定的未来来自哪里）

- **更确定 1（不变量）**：通用能力需要“长尾 + 恢复 + 切换”，这类结构几乎不可能从过度 clean 的数据里长出来。  
  - **信号**：评测是否转向迁移/恢复，而不是只看单任务成功率。
- **更确定 2（机制）**：数据质量不是“干净”，而是“信号密度”（关键窗口、失败恢复、覆盖、对齐）。  
  - **信号**：关键窗口/恢复数据占比是否上升，且回归集曲线可回归。
- **更确定 3（约束）**：规模化一定会遇到组织吞吐；能把采集/对齐/版本化做成系统的团队会赢。  
  - **信号**：人均采集吞吐、对齐成本、回归周期是否持续下降。

## 尽头坐标

### 远方尽头

机器人能在真实、混乱的家庭/开放环境里完成通用操作：会组合技能、会恢复、会在新环境里快速适配。

### 现实尽头（停止处）

- **过度 clean 的尽头**：泛化弱、遇到遮挡/不可达/失误恢复就崩
- **无目标的“脏”尽头**：多样性退化为噪声，训练不收敛或学不到可迁移结构
- **评测尽头**：只盯单任务成功率，误判模型是否在变“通用”
- **组织尽头**：管理与质控成本线性上升，规模化失败

### 退出条件 + 重启条件

- **退出条件（停机点）**
  - 数据更“干净”但迁移/泛化指标无提升（连续 ___ 次迭代）
  - 多样化采集导致训练不稳定且无法归因（连续 ___ 次 run）
  - 评测只剩单任务成功率，无法反映通用能力进展（持续 ___ 周）
- **重启条件（证据门槛）**
  - 迁移评测与恢复评测可稳定回归（回归集建立）
  - 目标驱动采集的人均效率提升（≥ ___%）且管理成本不线性增长
  - few-shot 微调样本需求下降（≥ ___%）

---

## 下一步（最小动作）

- 定义 3 个“有用目标”（每个都写：最小安全边界 + 允许自由度），用 7 天时间盒采一小批 diverse 数据。
- 做一次 A/B：同样数据量，`clean` vs `diverse`，只比迁移/恢复（别只比单任务成功率）。
- 把“信号密度”变成指标：关键窗口占比、失败恢复占比、覆盖度、对齐可用性（每周复盘一次）。

---

## 可投資標的（Long / Hedge / Short）

> 仅用于把“世界理解”翻译成可执行的交易表达，不构成投资建议。

**机制押注（假设/策略表达）**：具身数据的“护城河”更可能来自规模化采集与多样性配方，而不是过度 clean 的流程；因此受益链条偏向算力/传感器/数据中心与能够规模化落地的机器人与自动化生态。
**核验（2026-01-20）**：`SMH`、`BOTZ`、`ROBO` 已核验为对应 ETF；其余为美股常见 ticker，若你要替换为其它市场/品类应再核验。

### Long（做多：我相信它会发生）

- **主题**：数据规模化与采集基础设施（算力、传感器、渲染/仿真工具链、数据中心）  
  - **代表性标的（2–5）**：`NVDA`（训练/推理底座）、`SMH`（半导体篮子）、`BOTZ`/`ROBO`（机器人篮子，二选一）、`EQIX`（数据中心/互联）、`U`（工具链候选：渲染/仿真相关，按你风险偏好与理解决定是否纳入）  
  - **加密（可选）**：若把“数据 + 风险偏好”做 beta 暴露的一部分，可用 `BTC`/`BTC` ETF（视账户）作为高波动表达之一

### Hedge（对冲：我怕的是什么）

- **风险 1：隐私/合规/数据获取受限** → **工具**：分散化（篮子化）+ 指数 put；必要时减少“依赖数据获取叙事”的单票暴露  
- **风险 2：利率上行压制长久期成长估值** → **工具**：久期对冲（如 `TLT` 或利率相关工具，视账户）  
- **风险 3：制造业周期下行** → **工具**：工业/半导体篮子对冲或降低仓位

### Short（做空：我不相信它会发生，或认为被高估）

- **方向**：把“clean 数据=泛化”当作核心卖点的单一产品叙事（在真实世界分布下可能脆弱）。  
  - **表达方式**：优先用机器人/科技主题 ETF 的 put 或对冲对表达，避免裸空单票。  
  - **失效条件**：如果出现可回归证据显示“更 clean 的流程”在多任务迁移与恢复上持续胜出，应降低反向表达

### 观察信号（用于更新仓位）

- **信号 1（配方）**：行业是否从“数据清洁规则”转向“目标驱动 + 多样性 + 规模化”的 recipe  
- **信号 2（模态）**：触觉/力反馈/视触觉等关键模态是否普及（决定接触技能上限）  
- **信号 3（评测）**：评测是否从单任务成功率转向跨任务迁移 + 失败恢复  
- **复盘频率**：每月

---

## Plan Prompt（可选）

- 复用 `AGENT.md` 的验证/试运行模板（避免每篇重复模板）。
- 本篇关键槽位：3 个有用目标、最小安全边界、A/B 设计、迁移/恢复回归集、退出/重启阈值。

---

## 关联猜想（meta）

- `H-0004`：具身数据的关键不是“更干净”，而是更高信号密度（关键窗口/恢复/覆盖/对齐）+ 可回归评测与数据系统。

