# Digest：高阳（Spirit v1.5）——Clean Data Is the Enemy（具身数据范式：多样性 × Scale）

## 来源与类型

- **材料形态**：专访对话 + 官方博客翻译/整理（用户提供稿）
- **人物/背景**：高阳（千寻智能联合创始人；清华交叉信息研究院助理教授）
- **相关材料**
  - Spirit v1.5 官方博客：`https://www.spirit-ai.com/en/blog/spirit-v1-5`
  - 访谈中提及：Robot Challenge（原力灵机 × Hugging Face）榜单（需回到官方规则核验细节）
- **一手/二手**
  - 访谈部分：二手转写（以原音/原文为准）
  - 官方博客翻译：二手整理（以原文为准）
- **可追溯性与不确定性**
  - 文中出现的量化声称（如“人均有效采集时长提升约 200%”“研究人员投入降低约 60%”）需要回到官方 blog 或公开报告核验
  - 对“开源数据集多为 clean data、几乎没有 dirty data”的判断，属于立场与观察，缺少统一定义与广泛抽样

## 主题标签

具身智能｜VLA｜机器人数据｜clean data｜dirty data｜diversity｜goal-driven collection｜Scaling｜仿真数据｜人类数据｜in-context learning｜Diffusion Transformer｜Bitter Lesson

## 核心主张（可抽取为世界理解）

### 1) 具身通用操作的“模型层确定性”在上升

- 信号 1：数据规模增长下，能力提升斜率大（作者称超预期）
- 信号 2：训练基模过程中出现初步泛化能力（工程与系统问题逐步解决后显现）

### 2) 世界模型 vs VLA：不是对立路线

- 解决“通用操作”的最简输入输出是：**视觉 + 语言 → 动作**
- 只要 I/O 是 V+L→A，本质上就是 VLA；所谓世界模型更多是给 VLA 增强泛化的模块/损失（例如预测未来图像）

### 3) Clean Data 的诅咒：干净 ≠ 高质量（对 foundation model 而言）

- 常见做法：用脚本化任务、受控摆放、严格流程来保证复现难度低与成功率高（OXE / AgiBot / RoboCOIN 等被归为此类范式）
- 代价：
  - **低多样性**：数据孤岛化、任务割裂；缺乏失败恢复、切换、遮挡与不可达等“真实复杂性”
  - **难规模化**：任务设计与质控吃掉研究者精力，边际成本高
- 结论（主张）：在预训练阶段，“干净数据”可能是通用 robot foundation model 的敌人

### 4) 替代范式：开放式、目标驱动、多样化采集（diverse collection）

- **只保留一条原则**：做一些有用的事情（完成高层目标）
- **做法**：不给详细脚本，允许采集者在完成目标前提下自由发挥（过程随机、子任务自然串联）
- **预期收益**：
  - 多样性更高：对象、轨迹、环境变化、失败恢复、子任务切换
  - 更像“连续经验流形”，而不是“单任务片段”
  - 规模化更容易：管理与质控成本不线性增长，操作者体验更好
- **量化声称（需核验）**：人均有效采集时长提升 ~200%，研究人员直接投入降低 ~60%

### 5) 相关工程要点（访谈中给出的结构信息）

- **数据模态**：相机视觉 + 关节角 + 可选（末端 6D 位姿、速度等）
- **clean vs dirty 的定义（访谈口径）**
  - clean：流程规范化、约束多、动作被严格清洗后完成任务
  - dirty：公开数据中几乎未见；目标驱动自由发挥更接近“弱约束、多样化”
- **仿真数据**：当真实数据规模上来后，仿真增益变小，近期基本不再用（访谈口径）
- **人类数据**：动捕成本高、难规模化，尚未系统性大规模引入（访谈口径）

### 6) 模型结构（Spirit v1.5 的访谈口径）

- VLM 主干：`Qwen/Qwen3-VL-4B-Instruct`
- 动作侧：action expert（DiT / Diffusion Transformer），对动作序列做 denoise 生成动作
- 提供：策略推理 API（policy inference API）

## 反例/失败模式（尽头线索）

- 过度 clean：收敛容易但泛化差，遇到遮挡/不可达/失误恢复就失败
- 过度“脏”但缺乏目标：多样性变成噪声，难以形成可迁移技能（需要“有用目标”的牵引）
- 只看单任务成功率：忽视跨任务迁移与适配速度（few-shot/low-shot）

## 可验证预测（假设/推演）

- 在总数据量相同前提下：**多样化目标驱动预训练** > **脚本化任务特定预训练**（迁移与泛化更强）
- 随着数据规模扩大：多样化采集的边际收益更稳定（接近 Bitter Lesson：Diversity，然后 Scale）

## 输出去向建议

- **世界理解**：`world_understanding/embodied_data_clean_vs_diverse_spirit_v1_5.md`
- **可衍生清单**：一份“具身数据采集与质控清单”（目标定义、允许的自由度、退出条件）

