# 2025 LLM 年度回顾（Karpathy）：六个范式转变与它们改变了什么

> 这篇把 Karpathy 的年度回顾收敛成“世界理解”与可执行判断：哪些变化更像范式切换？它们如何改变训练、评测、产品与工作方式？你该如何用小成本验证，而不是被刷榜与叙事带跑？
>
> 来源 digest：`sources/2026-01-19_karpathy_llm_year_in_review_2025.md`（原文：`https://karpathy.bearblog.dev/year-in-review-2025/`）

---

## 概述（这篇解决什么选择/误区）

这篇解决的核心误区是：**把 LLM 的进展理解成“只要更大模型/更多预训练就会更强”**，以及把“榜单提升”误当成“真实能力提升”。

Karpathy 的视角认为，2025 的多个变化更像**训练范式、评测范式、产品形态与交互范式**的切换：

- 训练：从“预训练 + SFT + RLHF”稳定三段式，新增了 **RLVR** 的长优化阶段
- 推理：能力开始更像“测试时计算/思考时间”的函数
- 评测：对刷榜与基准的信任下降
- 产品：出现更厚的“应用层”（Cursor-like），以及“住在你电脑里的 agent”（Claude Code-like）
- 工程：氛围编码降低代码生产边际成本，改变软件的生产与生命周期
- 交互：从文本聊天走向多模态 GUI（图像/白板/应用）

---

## 框架/模型（1–3 个，给出使用条件）

### 1) “训练四段式”与新旋钮：RLVR + 测试时计算

- **模型**：预训练 → SFT → RLHF → **RLVR（可验证奖励强化学习）**
- **关键变化**：RLVR 允许在可自动验证的环境里进行更长时间的优化，模型会“自发”发展出分解问题、反复推敲与纠错的策略（作者描述为推理策略）。
- **新旋钮**：能力可作为“测试时计算量/思考时间”的函数被控制（更长轨迹、更多回合）。

**适用**：你在分析“能力为何提升”或“为何榜单陡增”，以及你在做推理型产品（数学、代码、可验证任务）。  
**不适用**：你需要的是强现实对齐、价值偏好细粒度对齐，而不是可验证目标的最优化。

### 2) 不均衡智能：在可验证邻域长“尖刺”

- **模型**：LLM 智能不是均匀增长，而是在可验证环境周围出现陡峭提升（尖刺），同时在其它维度可能仍像“困惑的小学生”。
- **后果**：基准测试（大量由可验证环境构建）更容易被优化，导致“榜单强 ≠ 真实稳”。

**适用**：你在做评测、采购模型、做安全边界与可靠性工作。  
**不适用**：你把模型当作纯工具、场景简单且容错高。

### 3) LLM 应用层：从模型到“编排系统”

- **模型**：LLM 实验室倾向培养通用“大学生”；应用层通过私有数据、传感器、执行器与反馈回路，把大学生组织成垂直“从业者”。
- **Cursor-like 组件**：上下文工程、多次调用编排（DAG）、GUI、人机协作、自主性滑块。
- **Claude Code-like 组件**：agent 运行在本地，利用你已有的安装、上下文、数据、密钥、配置与低延迟交互。

**适用**：你在做产品/业务落地、要把模型变成可交付能力。  
**不适用**：你只做模型 API 的单次调用（不需要工具、状态、反馈）。

---

## 材料分类与索引

- **类型**：观点文/趋势总结（作者第一人称）
- **主题**：训练范式（RLVR）、智能形态（不均衡）、评测（刷榜）、应用层（Cursor）、本地 agent（Claude Code）、氛围编码、LLM GUI（多模态交互）
- **可信度**：
  - **第一手/二手**：第一手观点
  - **可追溯性**：可追溯到原文，但大量属于解释/推演（不是论文级证明）
  - **利益相关**：作者长期在工业与工具链领域，有偏好“产品化/工程化视角”
  - **盲区**：缺少系统化数据支撑、不同实验室策略差异被简化
- **可抽取资产**：见 `sources/2026-01-19_karpathy_llm_year_in_review_2025.md`
- **输出去向**：`world_understanding/`（趋势/范式/路线），可衍生 `checklists/`

---

## 降维解剖（把“LLM 范式转变”压成可计算骨架）

### 第一性扫描（事实/约束/资源/风险）

- 可验证奖励存在 → 可以长时间优化 → 推理策略可能涌现
- 可验证基准占比高 → 优化目标容易“贴合基准邻域” → 评测失真风险上升
- 工具/环境/权限存在 → agent 能做事 → 同时带来数据泄露与不可控执行风险
- 交互成本真实存在：人不爱读长文本，更偏好视觉与空间表达

### 根本问题 $\\mathcal{O}$：行业在最大化什么？

一个可用的（粗糙但可操作）目标函数：

- **最大化**：可验证任务上的能力提升速度（单位算力产出） + 产品可交付性（能在现实流程里完成任务）
- **约束**：算力预算、评测可信度、可靠性与安全风险、延迟与成本、数据与权限合规

### 核心变量（≤10）+ 算子（≤5）

- **变量**：RLVR 训练时长、可验证环境覆盖面、测试时计算预算、长推理轨迹长度、基准邻域拟合程度、工具调用成功率、权限范围、泄露/越狱率、延迟、单位成本。
- **算子**：奖励优化、采样与重试、工具编排（DAG）、上下文选择（检索/压缩）、评测与回归（反刷榜）。

### 阶段切换信号（3 个）

1) 能力提升主要来自“更长优化/更长思考”而非更大预训练  
2) 评测从“看榜单”转向“看回归集/真实任务与对抗评测”  
3) 产品从“单次聊天”转向“编排系统 + 本地/私有上下文 + 反馈回路”

---

## 比较思考（发展史 × 情景 × 信号）

### 找祖先（机制类比）

- **控制台 → GUI（传统计算史）**：文本是机器偏好格式，但人偏好图像/空间；GUI 的出现改变了谁能使用计算。
- **编译器/库的普及 → 生产边际成本下降**：氛围编码把“写代码”的边际成本进一步压低，推动一次性/临时软件爆发。

### 未来情景（保守/基准/激进）+ 观察信号（假设/推演）

- **保守**：模型进步持续，但评测失真与安全问题限制落地，应用层更多做“包装”。  
  - 信号：安全事故频发；企业只敢在低风险流程使用；榜单波动与真实效果脱钩。
- **基准**：应用层变厚，本地 agent 普及；评测转向“真实任务回归集 + 对抗集”；多模态 GUI 出现稳定范式。  
  - 信号：出现行业标准的回归/对抗评测；“用于 X 的 Cursor”成为主流形态。
- **激进**：测试时计算与工具使用的结合，让“通用大学生”在多个垂直快速转成从业者。  
  - 信号：端到端交付任务成功率显著提升；工具编排标准化；权限与审计体系成熟。

---

## 尽头坐标

### 远方尽头

LLM 从“会说话的模型”变成“能可靠完成任务的系统”：可评估、可回归、可审计、可协作、可部署。

### 现实尽头（停止处）

- **评测尽头**：刷榜导致指标失真，团队在错误目标上优化
- **安全尽头**：越狱、数据泄露、不可控执行，迫使系统收缩权限或停止
- **成本/延迟尽头**：测试时计算更长 → 成本与延迟上升 → 用户与业务无法承受
- **组织尽头**：缺少真实反馈回路与私有数据/执行器，应用层难从“包装”升级为“从业者”

### 两问复盘

- **本来可以发生却为什么没发生？**  
  常见原因：没有真实任务回归集；只有榜单；权限与审计缺失；反馈回路断裂。
- **已堪堪发生却退回去复归不会发生？**  
  常见原因：上线后安全事故/成本爆炸；agent 失控；团队无法维护编排系统的复杂度。

### 退出条件 + 重启条件

- **退出条件（停机点）**
  - 连续 ___ 次迭代提升只体现在基准分数，真实任务成功率无提升
  - agent 触发 ___ 次高危权限误用/数据泄露/越狱事件
  - 单任务成本或 P95 延迟超过业务阈值（___ 元/次、___ 秒）
- **重启条件**
  - 建立并通过“真实任务回归集 + 对抗集”，且可稳定回归
  - 权限/审计/回放体系到位（可追责、可复盘）
  - 成本/延迟通过分层策略（缓存/路由/工具化）回到阈值内

---

## 短/中/长期利益（1–3 个月 / 1–3 年 / 5–10 年）

- **短期**：把评测从“榜单”迁移到“真实任务回归集”；做最小编排与权限边界
- **中期**：应用层变厚（DAG 编排、私有数据、工具、反馈回路）；本地 agent 与审计体系成熟
- **长期**：交互从文本聊天迁移到多模态 GUI（白板/应用/动画），LLM 成为新的计算范式底座

---

## MUST / SHOULD / MAY 清单

- **MUST**
  - 用真实任务回归集评估，而不是只看榜单
  - 为 agent 设计权限边界与审计回放（能复盘/能追责/能停机）
  - 把成本与延迟写进指标板（测试时计算越长越要量化）
- **SHOULD**
  - 用“编排系统”思维做产品：上下文工程 + 多次调用 DAG + GUI + 自主性滑块
  - 对可验证领域，显式衡量“思考时间”与成功率的函数关系
  - 对评测做对抗与反刷榜（不同分布、不同提示、不同工具链）
- **MAY**
  - 探索多模态 GUI 输出（信息图、白板、应用原型）
  - 把一次性软件/临时代码纳入流程（用于验证、排障、快速原型）

---

## 可投資標的（Long / Hedge / Short）

> 仅用于把“世界理解”翻译成可执行的交易表达，不构成投资建议。

**观点摘要**：价值更多沉到“应用编排 + 权限与审计 + 真实任务回归集 + 数据反馈回路”的厚软件层；同时算力与云仍是底座，但“谁能把能力接到真实工作流”才是分水岭。

### Long（做多：我相信它会发生）

- **主题**：云平台与企业软件把 LLM 变成“可审计的生产力系统”（工作流/DAG/权限/数据）  
  - **代表性标的（2–5）**：`MSFT`（Copilot + 企业分发 + 云）、`AMZN`（云 + 工具生态）、`GOOGL`（模型/工具/云）、`IGV`（软件篮子）、`SKYY`（云篮子）  
  - **可选补充**：网络安全（权限/审计/防泄漏成为默认成本）：`HACK`/`BUG`（二选一）

### Hedge（对冲：我怕的是什么）

- **风险 1：监管/安全事故导致工具权限收缩** → **工具**：适度配置网络安全篮子（`HACK`/`BUG`），或对增长暴露用 `QQQ` 保护性 put  
- **风险 2：成本反弹（推理价格、带宽、电力）** → **工具**：降低单一应用层暴露，偏向“平台 + 现金流”篮子；必要时用指数对冲锁住回撤  
- **风险 3：风险偏好切换** → **工具**：波动率/指数期权结构（优先限损）

### Short（做空：我不相信它会发生，或认为被高估）

- **方向**：高营销低护城河的“Agent/RAG 包装层”主题（缺少真实任务回归与权限治理，容易被平台吞并）。  
  - **表达方式**：优先用软件/云主题 ETF 的 put 或对冲对表达，避免裸空单票。  
  - **候选篮子**：`CLOU`（云软件主题）/`IGV`（软件主题，二选一）

### 观察信号（用于更新仓位）

- **信号 1（落地）**：企业“真实任务回归集 + 权限审计”是否成为默认配置（产品形态从聊天→编排系统）  
- **信号 2（单位经济）**：推理成本/延迟下降是否转化为可规模化付费（而非 demo）  
- **信号 3（平台吞并）**：平台能力下沉后，中间层的议价权是否持续下降  
- **复盘频率**：每月（财报季提高频率）

---

## Plan Prompt（可直接复制给 Agent 执行｜小成本验证）

```text
你是执行代理。请在不编造信息的前提下，帮我把“Karpathy 2025 LLM 年度回顾”的观点，落到我自己的场景里，完成一次小成本验证。

## 背景
我的产品/工作流/任务：<一句话>
我目前用的模型与形态：<聊天/编排系统/本地 agent/多模态>
我目前的评测方式：<榜单/内部回归集/线上指标>

## 目标（要拿到的证据）
- 证据1：给出 1 份“真实任务回归集”最小方案（10–30 条样本即可），并说明如何防刷榜
- 证据2：给出 1 份权限与审计最小方案（允许/禁止的工具、日志字段、停机点）
- 证据3：给出 1 个“思考时间/测试时计算”旋钮实验（预算、预期曲线、判定标准）
- 证据4：输出退出条件与重启条件（阈值必须可观测）

## 约束
- 时间盒：90 分钟
- 投入上限：<钱/人天/算力>
- 隐私：不要写入任何真实个人隐私或敏感信息

## 你要做的事
1) 把最危险假设写成可证伪陈述（3 条）
2) 设计最小实验（动作+成本+预期信号+判定标准）
3) 写出退出条件与重启条件
4) 输出一段可直接粘贴到 `worksheets/decision_one_pager.md` 的一页总结
```

