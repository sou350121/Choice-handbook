# 具身数据范式：别追求“干净”，要追求“有用 + 多样”（Spirit v1.5 / 高阳）

> 核心观点：抛弃几乎所有“保证干净数据”的规则，只保留一条原则——做一些有用的事情；用目标驱动的自由过程换取多样性，再用规模化把能力推上去。
>
> 来源 digest：`sources/2026-01-19_gaoyang_spirit_v1_5_clean_data_enemy.md`（含官方 blog：`https://www.spirit-ai.com/en/blog/spirit-v1-5`）

---

## 概述（这篇解决什么选择/误区）

在机器人/具身智能的数据问题上，最常见的误区是把：

- **高质量数据 = 干净数据（clean）**  
- **模型能学会 = 数据要被强约束、强筛选、强脚本化**

这篇材料提出反直觉主张：对“通用 robot foundation model”而言，**过于干净的数据可能是敌人**。更好的方向是：

- **目标驱动**（只规定“做什么有用的事”）
- **过程自由**（允许操作者随机发挥）
- **多样性优先**（diversity）
- **然后 scale**（Bitter Lesson：Diversity，然后 Scale）

---

## 框架/模型（1–3 个，给出使用条件）

### 1) “Clean vs Diverse”不是数据卫生问题，而是泛化策略选择

- **Clean（强约束/强脚本）**：易收敛、复现难度低、单任务成功率好看
- **Diverse（弱约束/目标驱动）**：更像真实生活流，包含切换、失败恢复、遮挡、不可达等复杂性

**适用**：你在做 foundation model 预训练、跨任务迁移、希望模型学“技能组合”而非“单动作”。  
**不适用**：你只做一个固定任务、固定环境、且更看重短期收敛与可控复现（但也要防止过拟合）。

### 2) “只保留一条原则”：目标驱动采集（Goal-driven collection）

把采集规则从“如何做”改成“做成什么”：

- 规则从脚本变成目标（high-level objective）
- 过程允许自由发挥（子任务自然串联）
- 记录连续经验流（而不是孤立片段）

**适用**：你想提高数据多样性，并降低“每个新任务都要重新设计采集流程”的管理成本。  
**不适用**：你没有清晰目标、也没有最小安全边界，导致“多样”退化为随机噪声。

### 3) VLA vs 世界模型：不是路线对立，而是增强模块

在“通用操作”问题上，最自然 I/O 是：

- **视觉 + 语言 → 动作**

只要 I/O 是 V+L→A，本质上就是 VLA。所谓世界模型更多是作为增强模块（例如预测未来图像）提升泛化能力，而不是与 VLA 对立的路线。

---

## 材料分类与索引

- **类型**：专访对话 + 官方博客翻译/整理（二手材料，以原文为准）
- **主题**：数据范式（clean vs diverse）、VLA 与世界模型关系、数据配方探索、仿真/人类数据取舍、Bitter Lesson
- **可信度提示**：
  - 文中的量化声称与榜单结果需回到官方材料核验
  - “开源数据集几乎都是 clean”属于立场与观察，需明确你的定义与抽样范围
- **可抽取资产**：见 `sources/2026-01-19_gaoyang_spirit_v1_5_clean_data_enemy.md`

---

## 降维解剖（把“数据范式”压成可计算骨架）

### 第一性扫描（事实/约束/资源/风险）

- 机器人数据采集天然昂贵：脚本化与质控会把管理成本做成线性增长
- 真实世界任务天然“脏”：遮挡、不可达、失败恢复、状态切换是常态
- foundation model 目标不是复现单一轨迹，而是学会可迁移技能组合

### 根本问题 $\\mathcal{O}$：你在最大化什么？

一个可执行目标函数：

- **最大化**：跨任务迁移能力 + few-shot 微调效率
- **约束**：采集成本、管理成本、训练稳定性、风险与安全边界

### 核心变量（≤10）+ 算子（≤5）

- **变量**：任务多样性、连续性（是否串联）、失败恢复比例、环境变化幅度、遮挡/可达性分布、目标完成率、数据规模、采集人均效率、研究人员介入成本、微调样本需求。
- **算子**：目标定义、采集自由度设置、最小安全约束、训练（预训练+微调）、评测（迁移/泛化/恢复）。

### 阶段切换信号（3 个）

1) 数据规模增长下能力斜率仍大（scaling 继续有效）  
2) 少样本微调步骤显著下降（迁移变快）  
3) 从“单任务成功率”转向“跨任务组合与恢复能力”的评测体系建立

---

## 比较思考（发展史 × 情景 × 信号）

### 结构相似的祖先（机制类比）

- **自动驾驶数据飞轮**：真实世界的“长尾与脏”不可避免；关键是把采集、标注/管理、训练、回归做成系统。
- **机器人 sim-to-real**：追求“可控仿真/可控流程”能起步，但泛化往往卡在真实世界的混乱分布。

### 案例补丁：灵巧手的数据金字塔（为什么“干净”不等于“有用”）

灵巧手的访谈材料提供了一个很好的“数据策略”对照样本：同样是操作任务，**越接近真实接触/双手协同/力控的技能，数据越稀缺、越贵、也越决定泛化上限**。

- **金字塔尖（少量高质）**：遥操作数据——最能直接提升效果，但难规模化；任务越难（如开可乐/剪纸/折纸）越难采
- **金字塔底（海量低信噪）**：人类视频——量大但缺少力/精确动作映射；如何“最好利用”仍是研究问题
- **中间层（可扩但有偏差）**：仿真/RL、专用采集装置等——对某些本体有效，但在复杂接触上 sim2real 仍是硬坎

把它映射回本篇的“clean vs diverse”主张：**如果你只采“干净、脚本化、自由空间”的数据，很可能在关键接触窗口（bottleneck moments）上永远缺粮**；而真正决定能力上限的，恰恰是那些更“脏”的接触与恢复片段。

详细拆解见：[`dexterous_hands_hardware_algorithms.md`](./dexterous_hands_hardware_algorithms.md)（含“成功率门槛”“触觉与遮挡”“产能/装配约束”等）。

### 未来情景（保守/基准/激进）+ 观察信号（假设/推演）

- **保守**：clean 数据仍主导，模型以“更易复现”换“较弱泛化”。  
  - 信号：评测仍以单任务成功率为主；跨任务迁移提升慢。
- **基准**：目标驱动多样化采集成为主流 recipe；配合更好的训练与评测体系。  
  - 信号：更少人工规则、更大规模采集；few-shot 微调显著更快。
- **激进**：出现具身版“GPT-3→GPT-4”级模型跃迁（访谈期待）。  
  - 信号：in-context learning 在操作领域真正可用（给演示就能学会）。

---

## 尽头坐标（唐诺）

### 远方尽头

机器人能在真实、混乱的家庭/开放环境里完成通用操作：会组合技能、会恢复、会在新环境里快速适配。

### 现实尽头（停止处）

- **过度 clean 的尽头**：泛化弱、遇到遮挡/不可达/失误恢复就崩
- **无目标的“脏”尽头**：多样性退化为噪声，训练不收敛或学不到可迁移结构
- **评测尽头**：只盯单任务成功率，误判模型是否在变“通用”
- **组织尽头**：管理与质控成本线性上升，规模化失败

### 退出条件 + 重启条件

- **退出条件（停机点）**
  - 数据更“干净”但迁移/泛化指标无提升（连续 ___ 次迭代）
  - 多样化采集导致训练不稳定且无法归因（连续 ___ 次 run）
  - 评测只剩单任务成功率，无法反映通用能力进展（持续 ___ 周）
- **重启条件（证据门槛）**
  - 迁移评测与恢复评测可稳定回归（回归集建立）
  - 目标驱动采集的人均效率提升（≥ ___%）且管理成本不线性增长
  - few-shot 微调样本需求下降（≥ ___%）

---

## MUST / SHOULD / MAY 清单

- **MUST**
  - 定义“有用目标”（否则多样性会变噪声）
  - 建立跨任务迁移与恢复评测（别只看单任务成功率）
  - 记录连续轨迹与关键模态（视觉 + 关节/末端位姿等）
- **SHOULD**
  - 放松过程约束，保留最小安全边界
  - 让采集者自由发挥，鼓励任务串联与失败恢复
  - 随模型升级持续调整数据配方（recipe 不是一次性）
- **MAY**
  - 探索 in-context learning 的具身形式（演示→学会）
  - 在真实数据足够后逐步减少仿真依赖（以实际增益为准）

---

## 练习（可复制填写）

- 我们要让机器人做的“有用目标”：__________（一句话）
- 允许的自由度：哪些过程不规定？哪些安全边界必须有？__________
- 我们期望采到的“多样性”：对象/环境/失败恢复/任务切换（各写 1 条）
- 我们的评测：迁移任务 ___ 个；恢复任务 ___ 个；新环境任务 ___ 个
- 退出条件：__________
- 重启条件：__________

---

## Plan Prompt（可直接复制给 Agent 执行｜小成本验证）

```text
你是执行代理。请在不编造信息的前提下，帮我把“clean vs diverse 的具身数据范式”落到我的数据采集与训练里，完成一次小成本验证。

## 背景
我的机器人平台/传感器：<相机/关节角/末端位姿…>
我现在的数据范式：<clean脚本化 / 目标驱动多样化 / 混合>
我关心的通用能力：<跨任务迁移/失败恢复/新环境适配>

## 目标（要拿到的证据）
- 证据1：定义 3 个“有用目标”，并给出每个目标的最小安全边界与允许自由度
- 证据2：设计一个 A/B 采集对比（clean vs diverse），总数据量相同，评测迁移/恢复
- 证据3：给出评测回归集（至少 10 个任务/场景片段）与判定标准
- 证据4：写出退出条件与重启条件（可观测阈值）

## 约束
- 时间盒：7 天（可调整）
- 投入上限：<人天/设备占用/预算>
- 隐私：不要写入任何真实个人隐私或敏感信息

## 你要做的事
1) 把最危险假设写成可证伪陈述（3 条）
2) 设计最小实验（动作+成本+预期信号+判定标准）
3) 写出退出条件与重启条件
4) 输出一段可直接粘贴到 `worksheets/decision_one_pager.md` 的一页总结
```

